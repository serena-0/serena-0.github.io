[
  {
    "title": "Introducing OptiMind, a research model designed for optimization",
    "url": "https://huggingface.co/blog/microsoft/optimind",
    "source": "Hugging Face Blog",
    "published_at": "2026-01-15",
    "raw_snippet": "",
    "ai_summary": "",
    "ai_generated": false,
    "tags": [],
    "hot_score": 14,
    "sources": [
      "Hugging Face Blog"
    ]
  },
  {
    "title": "Open Responses: What you need to know",
    "url": "https://huggingface.co/blog/open-responses",
    "source": "Hugging Face Blog",
    "published_at": "2026-01-15",
    "raw_snippet": "",
    "ai_summary": "",
    "ai_generated": false,
    "tags": [],
    "hot_score": 14,
    "sources": [
      "Hugging Face Blog"
    ]
  },
  {
    "title": "NVIDIA Cosmos Reason 2 Brings Advanced Reasoning To Physical AI",
    "url": "https://huggingface.co/blog/nvidia/nvidia-cosmos-reason-2-brings-advanced-reasoning",
    "source": "Hugging Face Blog",
    "published_at": "2026-01-05",
    "raw_snippet": "",
    "ai_summary": "",
    "ai_generated": false,
    "tags": [],
    "hot_score": 11,
    "sources": [
      "Hugging Face Blog"
    ]
  },
  {
    "title": "Introducing Falcon-H1-Arabic: Pushing the Boundaries of Arabic Language AI with Hybrid Architecture",
    "url": "https://huggingface.co/blog/tiiuae/falcon-h1-arabic",
    "source": "Hugging Face Blog",
    "published_at": "2026-01-05",
    "raw_snippet": "",
    "ai_summary": "",
    "ai_generated": false,
    "tags": [],
    "hot_score": 11,
    "sources": [
      "Hugging Face Blog"
    ]
  },
  {
    "title": "NVIDIA brings agents to life with DGX Spark and Reachy Mini",
    "url": "https://huggingface.co/blog/nvidia-reachy-mini",
    "source": "Hugging Face Blog",
    "published_at": "2026-01-05",
    "raw_snippet": "",
    "ai_summary": "",
    "ai_generated": false,
    "tags": [],
    "hot_score": 11,
    "sources": [
      "Hugging Face Blog"
    ]
  },
  {
    "title": "面向临床的心电图AI，上智院、复旦等提出CLEAR-HUG框架实现诊断性能与可解释性双突破",
    "url": "https://www.jiqizhixin.com/articles/2026-01-16-10",
    "source": "机器之心",
    "published_at": "2026-01-16",
    "raw_snippet": "",
    "ai_summary": "",
    "ai_generated": false,
    "tags": [],
    "hot_score": 6,
    "sources": [
      "机器之心"
    ]
  },
  {
    "title": "神同步OpenAI！中国团队Deep Principle领衔发布LLMs for Science评测，引爆外网",
    "url": "https://www.jiqizhixin.com/articles/2026-01-16-9",
    "source": "机器之心",
    "published_at": "2026-01-16",
    "raw_snippet": "",
    "ai_summary": "",
    "ai_generated": false,
    "tags": [],
    "hot_score": 6,
    "sources": [
      "机器之心"
    ]
  },
  {
    "title": "美团又上新模型，8个Thinker齐开工，能顶个诸葛亮？",
    "url": "https://www.jiqizhixin.com/articles/2026-01-16-8",
    "source": "机器之心",
    "published_at": "2026-01-16",
    "raw_snippet": "",
    "ai_summary": "",
    "ai_generated": false,
    "tags": [],
    "hot_score": 6,
    "sources": [
      "机器之心"
    ]
  },
  {
    "title": "AI Survival Stories: a Taxonomic Analysis of AI Existential Risk",
    "url": "https://arxiv.org/abs/2601.09765",
    "source": "arXiv cs.AI",
    "published_at": "2026-01-16",
    "raw_snippet": "arXiv:2601.09765v1 Announce Type: new Abstract: Since the release of ChatGPT, there has been a lot of debate about whether AI systems pose an existential risk to humanity. This paper develops a general framework for thinking about the existential risk of AI systems. We analyze a two premise argument that AI systems pos…",
    "ai_summary": "",
    "ai_generated": false,
    "tags": [],
    "hot_score": 5,
    "sources": [
      "arXiv cs.AI"
    ]
  },
  {
    "title": "GUI-Eyes: Tool-Augmented Perception for Visual Grounding in GUI Agents",
    "url": "https://arxiv.org/abs/2601.09770",
    "source": "arXiv cs.AI",
    "published_at": "2026-01-16",
    "raw_snippet": "arXiv:2601.09770v1 Announce Type: new Abstract: Recent advances in vision-language models (VLMs) and reinforcement learning (RL) have driven progress in GUI automation. However, most existing methods rely on static, one-shot visual inputs and passive perception, lacking the ability to adaptively determine when, whether…",
    "ai_summary": "",
    "ai_generated": false,
    "tags": [],
    "hot_score": 5,
    "sources": [
      "arXiv cs.AI"
    ]
  },
  {
    "title": "PCN-Rec: Agentic Proof-Carrying Negotiation for Reliable Governance-Constrained Recommendation",
    "url": "https://arxiv.org/abs/2601.09771",
    "source": "arXiv cs.AI",
    "published_at": "2026-01-16",
    "raw_snippet": "arXiv:2601.09771v1 Announce Type: new Abstract: Modern LLM-based recommenders can generate compelling ranked lists, but they struggle to reliably satisfy governance constraints such as minimum long-tail exposure or diversity requirements. We present PCN-Rec, a proof-carrying negotiation pipeline that separates natural-…",
    "ai_summary": "",
    "ai_generated": false,
    "tags": [],
    "hot_score": 5,
    "sources": [
      "arXiv cs.AI"
    ]
  },
  {
    "title": "Antisocial behavior towards large language model users: experimental evidence",
    "url": "https://arxiv.org/abs/2601.09772",
    "source": "arXiv cs.AI",
    "published_at": "2026-01-16",
    "raw_snippet": "arXiv:2601.09772v1 Announce Type: new Abstract: The rapid spread of large language models (LLMs) has raised concerns about the social reactions they provoke. Prior research documents negative attitudes toward AI users, but it remains unclear whether such disapproval translates into costly action. We address this questi…",
    "ai_summary": "",
    "ai_generated": false,
    "tags": [],
    "hot_score": 5,
    "sources": [
      "arXiv cs.AI",
      "arXiv cs.CL"
    ]
  },
  {
    "title": "Improving Chain-of-Thought for Logical Reasoning via Attention-Aware Intervention",
    "url": "https://arxiv.org/abs/2601.09805",
    "source": "arXiv cs.AI",
    "published_at": "2026-01-16",
    "raw_snippet": "arXiv:2601.09805v1 Announce Type: new Abstract: Modern logical reasoning with LLMs primarily relies on employing complex interactive frameworks that decompose the reasoning process into subtasks solved through carefully designed prompts or requiring external resources (e.g., symbolic solvers) to exploit their strong lo…",
    "ai_summary": "",
    "ai_generated": false,
    "tags": [],
    "hot_score": 5,
    "sources": [
      "arXiv cs.AI",
      "arXiv cs.LG"
    ]
  },
  {
    "title": "Thinking Long, but Short: Stable Sequential Test-Time Scaling for Large Reasoning Models",
    "url": "https://arxiv.org/abs/2601.09855",
    "source": "arXiv cs.AI",
    "published_at": "2026-01-16",
    "raw_snippet": "arXiv:2601.09855v1 Announce Type: new Abstract: Sequential test-time scaling is a promising training-free method to improve large reasoning model accuracy, but as currently implemented, significant limitations have been observed. Inducing models to think for longer can increase their accuracy, but as the length of reas…",
    "ai_summary": "",
    "ai_generated": false,
    "tags": [],
    "hot_score": 5,
    "sources": [
      "arXiv cs.AI",
      "arXiv cs.CL"
    ]
  },
  {
    "title": "A Scoping Review of the Ethical Perspectives on Anthropomorphising Large Language Model-Based Conversational Agents",
    "url": "https://arxiv.org/abs/2601.09869",
    "source": "arXiv cs.AI",
    "published_at": "2026-01-16",
    "raw_snippet": "arXiv:2601.09869v1 Announce Type: new Abstract: Anthropomorphisation -- the phenomenon whereby non-human entities are ascribed human-like qualities -- has become increasingly salient with the rise of large language model (LLM)-based conversational agents (CAs). Unlike earlier chatbots, LLM-based CAs routinely generate…",
    "ai_summary": "",
    "ai_generated": false,
    "tags": [],
    "hot_score": 5,
    "sources": [
      "arXiv cs.AI"
    ]
  },
  {
    "title": "Epistemology gives a Future to Complementarity in Human-AI Interactions",
    "url": "https://arxiv.org/abs/2601.09871",
    "source": "arXiv cs.AI",
    "published_at": "2026-01-16",
    "raw_snippet": "arXiv:2601.09871v1 Announce Type: new Abstract: Human-AI complementarity is the claim that a human supported by an AI system can outperform either alone in a decision-making process. Since its introduction in the human-AI interaction literature, it has gained traction by generalizing the reliance paradigm and by offeri…",
    "ai_summary": "",
    "ai_generated": false,
    "tags": [],
    "hot_score": 5,
    "sources": [
      "arXiv cs.AI",
      "arXiv cs.LG"
    ]
  },
  {
    "title": "Beyond Rule-Based Workflows: An Information-Flow-Orchestrated Multi-Agents Paradigm via Agent-to-Agent Communication from CORAL",
    "url": "https://arxiv.org/abs/2601.09883",
    "source": "arXiv cs.AI",
    "published_at": "2026-01-16",
    "raw_snippet": "arXiv:2601.09883v1 Announce Type: new Abstract: Most existing Large Language Model (LLM)-based Multi-Agent Systems (MAS) rely on predefined workflows, where human engineers enumerate task states in advance and specify routing rules and contextual injections accordingly. Such workflow-driven designs are essentially rule…",
    "ai_summary": "",
    "ai_generated": false,
    "tags": [],
    "hot_score": 5,
    "sources": [
      "arXiv cs.AI"
    ]
  },
  {
    "title": "Continuum Memory Architectures for Long-Horizon LLM Agents",
    "url": "https://arxiv.org/abs/2601.09913",
    "source": "arXiv cs.AI",
    "published_at": "2026-01-16",
    "raw_snippet": "arXiv:2601.09913v1 Announce Type: new Abstract: Retrieval-augmented generation (RAG) has become the default strategy for providing large language model (LLM) agents with contextual knowledge. Yet RAG treats memory as a stateless lookup table: information persists indefinitely, retrieval is read-only, and temporal conti…",
    "ai_summary": "",
    "ai_generated": false,
    "tags": [],
    "hot_score": 5,
    "sources": [
      "arXiv cs.AI"
    ]
  }
]