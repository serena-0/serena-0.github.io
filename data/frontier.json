[
  {
    "title": "FineInstructions: Scaling Synthetic Instructions to Pre-Training Scale",
    "url": "https://huggingface.co/papers/2601.22146",
    "source": "HF Trending Papers",
    "published_at": "2026-01-30",
    "raw_snippet": "Large language models can be pre-trained from scratch using synthetic instruction-response pairs generated from unstructured text corpora, outperforming traditional methods on benchmarks measuring response quality. AI-generated summary Due to limited supervised training data, large language models (LLMs) are typically…",
    "ai_summary": "",
    "ai_generated": false,
    "tags": [],
    "hot_score": 15,
    "sources": [
      "HF Trending Papers"
    ]
  },
  {
    "title": "Scalable Power Sampling: Unlocking Efficient, Training-Free Reasoning for LLMs via Distribution Sharpening",
    "url": "https://huggingface.co/papers/2601.21590",
    "source": "HF Trending Papers",
    "published_at": "2026-01-30",
    "raw_snippet": "A theoretically grounded method for improving large language model reasoning performance through distribution sharpening without iterative sampling or external rewards, achieving comparable results to reinforcement learning post-training with significantly reduced computational costs. AI-generated summary Reinforcement…",
    "ai_summary": "",
    "ai_generated": false,
    "tags": [],
    "hot_score": 15,
    "sources": [
      "HF Trending Papers"
    ]
  },
  {
    "title": "Discovering Hidden Gems in Model Repositories",
    "url": "https://huggingface.co/papers/2601.22157",
    "source": "HF Trending Papers",
    "published_at": "2026-01-30",
    "raw_snippet": "Hidden superior models exist in public repositories but are overlooked due to inefficient discovery methods; a multi-armed bandit approach using shared query sets and aggressive elimination significantly accelerates identification of top-performing models. AI-generated summary Public repositories host millions of fine-…",
    "ai_summary": "",
    "ai_generated": false,
    "tags": [],
    "hot_score": 15,
    "sources": [
      "HF Trending Papers"
    ]
  },
  {
    "title": "Mechanistic Data Attribution: Tracing the Training Origins of Interpretable LLM Units",
    "url": "https://huggingface.co/papers/2601.21996",
    "source": "HF Trending Papers",
    "published_at": "2026-01-30",
    "raw_snippet": "Mechnistic Data Attribution framework traces interpretable units to specific training samples using influence functions, demonstrating causal relationships between data structure and neural circuit formation in language models. AI-generated summary While Mechanistic Interpretability has identified interpretable circuit…",
    "ai_summary": "",
    "ai_generated": false,
    "tags": [],
    "hot_score": 15,
    "sources": [
      "HF Trending Papers"
    ]
  },
  {
    "title": "ECO: Quantized Training without Full-Precision Master Weights",
    "url": "https://huggingface.co/papers/2601.22101",
    "source": "HF Trending Papers",
    "published_at": "2026-01-30",
    "raw_snippet": "Error-compensating optimizer eliminates memory overhead from master weights in quantized LLM training while maintaining near-lossless accuracy. AI-generated summary Quantization has significantly improved the compute and memory efficiency of Large Language Model (LLM) training. However, existing approaches still rely o…",
    "ai_summary": "",
    "ai_generated": false,
    "tags": [],
    "hot_score": 15,
    "sources": [
      "HF Trending Papers"
    ]
  },
  {
    "title": "AgentLongBench: A Controllable Long Benchmark For Long-Contexts Agents via Environment Rollouts",
    "url": "https://huggingface.co/papers/2601.20730",
    "source": "HF Trending Papers",
    "published_at": "2026-01-30",
    "raw_snippet": "AgentLongBench evaluates large language models as autonomous agents through dynamic environment interactions, revealing challenges in handling high-information-density tool responses compared to memory fragmentation in long conversations. AI-generated summary The evolution of Large Language Models (LLMs) into autonomou…",
    "ai_summary": "",
    "ai_generated": false,
    "tags": [],
    "hot_score": 15,
    "sources": [
      "HF Trending Papers"
    ]
  },
  {
    "title": "FROST: Filtering Reasoning Outliers with Attention for Efficient Reasoning",
    "url": "https://huggingface.co/papers/2601.19001",
    "source": "HF Trending Papers",
    "published_at": "2026-01-30",
    "raw_snippet": "FROST is an attention-aware method that improves reasoning efficiency by pruning uncritical paths and removing reasoning outliers, leading to reduced token usage and improved accuracy. AI-generated summary We propose FROST, an attention-aware method for efficient reasoning. Unlike traditional approaches, FROST leverage…",
    "ai_summary": "",
    "ai_generated": false,
    "tags": [],
    "hot_score": 15,
    "sources": [
      "HF Trending Papers"
    ]
  },
  {
    "title": "Idea2Story: An Automated Pipeline for Transforming Research Concepts into Complete Scientific Narratives",
    "url": "https://huggingface.co/papers/2601.20833",
    "source": "HF Trending Papers",
    "published_at": "2026-01-30",
    "raw_snippet": "Offline knowledge construction through structured methodological graphs enables more reliable and scalable autonomous scientific discovery by reducing reliance on real-time literature processing. AI-generated summary Autonomous scientific discovery with large language model (LLM)-based agents has recently made substant…",
    "ai_summary": "",
    "ai_generated": false,
    "tags": [],
    "hot_score": 15,
    "sources": [
      "HF Trending Papers"
    ]
  },
  {
    "title": "One-step Latent-free Image Generation with Pixel Mean Flows",
    "url": "https://huggingface.co/papers/2601.22158",
    "source": "HF Trending Papers",
    "published_at": "2026-01-30",
    "raw_snippet": "Pixel MeanFlow introduces a one-step latent-free image generation method by separating network output space from loss space, achieving strong performance on ImageNet at multiple resolutions. AI-generated summary Modern diffusion/flow-based models for image generation typically exhibit two core characteristics: (i) usin…",
    "ai_summary": "",
    "ai_generated": false,
    "tags": [],
    "hot_score": 15,
    "sources": [
      "HF Trending Papers"
    ]
  },
  {
    "title": "Hybrid Linear Attention Done Right: Efficient Distillation and Effective Architectures for Extremely Long Contexts",
    "url": "https://huggingface.co/papers/2601.22156",
    "source": "HF Trending Papers",
    "published_at": "2026-01-30",
    "raw_snippet": "HALO enables efficient conversion of Transformer models to RNN-attention hybrid architectures with improved long-context performance using minimal training data. AI-generated summary Hybrid Transformer architectures, which combine softmax attention blocks and recurrent neural networks (RNNs), have shown a desirable per…",
    "ai_summary": "",
    "ai_generated": false,
    "tags": [],
    "hot_score": 15,
    "sources": [
      "HF Trending Papers"
    ]
  },
  {
    "title": "PLANING: A Loosely Coupled Triangle-Gaussian Framework for Streaming 3D Reconstruction",
    "url": "https://huggingface.co/papers/2601.22046",
    "source": "HF Trending Papers",
    "published_at": "2026-01-30",
    "raw_snippet": "PLANING presents an efficient streaming reconstruction framework that combines explicit geometric primitives with neural Gaussians to achieve high-quality rendering and accurate geometry simultaneously through decoupled optimization. AI-generated summary Streaming reconstruction from monocular image sequences remains c…",
    "ai_summary": "",
    "ai_generated": false,
    "tags": [],
    "hot_score": 15,
    "sources": [
      "HF Trending Papers"
    ]
  },
  {
    "title": "BMAM: Brain-inspired Multi-Agent Memory Framework",
    "url": "https://huggingface.co/papers/2601.20465",
    "source": "HF Trending Papers",
    "published_at": "2026-01-30",
    "raw_snippet": "BMAM presents a brain-inspired multi-agent memory architecture that decomposes memory into specialized subsystems to address long-term reasoning challenges in language-model-based agents. AI-generated summary Language-model-based agents operating over extended interaction horizons face persistent challenges in preservi…",
    "ai_summary": "",
    "ai_generated": false,
    "tags": [],
    "hot_score": 15,
    "sources": [
      "HF Trending Papers"
    ]
  },
  {
    "title": "Everything in Its Place: Benchmarking Spatial Intelligence of Text-to-Image Models",
    "url": "https://huggingface.co/papers/2601.20354",
    "source": "HF Trending Papers",
    "published_at": "2026-01-30",
    "raw_snippet": "A new benchmark and dataset are introduced to evaluate and improve spatial reasoning capabilities in text-to-image models through information-dense prompts and fine-tuning. AI-generated summary Text-to-image (T2I) models have achieved remarkable success in generating high-fidelity images, but they often fail in handlin…",
    "ai_summary": "",
    "ai_generated": false,
    "tags": [],
    "hot_score": 15,
    "sources": [
      "HF Trending Papers"
    ]
  },
  {
    "title": "Spotlighting Task-Relevant Features: Object-Centric Representations for Better Generalization in Robotic Manipulation",
    "url": "https://huggingface.co/papers/2601.21416",
    "source": "HF Trending Papers",
    "published_at": "2026-01-30",
    "raw_snippet": "Slot-Based Object-Centric Representations outperform global and dense feature representations in robotic manipulation tasks by providing better generalization under visual distribution shifts. AI-generated summary The generalization capabilities of robotic manipulation policies are heavily influenced by the choice of v…",
    "ai_summary": "",
    "ai_generated": false,
    "tags": [],
    "hot_score": 15,
    "sources": [
      "HF Trending Papers"
    ]
  },
  {
    "title": "STORM: Slot-based Task-aware Object-centric Representation for robotic Manipulation",
    "url": "https://huggingface.co/papers/2601.20381",
    "source": "HF Trending Papers",
    "published_at": "2026-01-30",
    "raw_snippet": "STORM enhances robotic manipulation by adapting visual foundation models with semantic-aware slots through multi-phase training, improving generalization and control performance. AI-generated summary Visual foundation models provide strong perceptual features for robotics, but their dense representations lack explicit…",
    "ai_summary": "",
    "ai_generated": false,
    "tags": [],
    "hot_score": 15,
    "sources": [
      "HF Trending Papers"
    ]
  },
  {
    "title": "MetricAnything: Scaling Metric Depth Pretraining with Noisy Heterogeneous Sources",
    "url": "https://huggingface.co/papers/2601.22054",
    "source": "HF Trending Papers",
    "published_at": "2026-01-30",
    "raw_snippet": "Metric Anything presents a scalable pretraining framework for metric depth estimation that leverages diverse 3D data and sparse metric prompts to achieve superior performance across multiple vision tasks. AI-generated summary Scaling has powered recent advances in vision foundation models, yet extending this paradigm t…",
    "ai_summary": "",
    "ai_generated": false,
    "tags": [],
    "hot_score": 15,
    "sources": [
      "HF Trending Papers"
    ]
  },
  {
    "title": "OCRVerse: Towards Holistic OCR in End-to-End Vision-Language Models",
    "url": "https://huggingface.co/papers/2601.21639",
    "source": "HF Trending Papers",
    "published_at": "2026-01-30",
    "raw_snippet": "OCRVerse is a novel end-to-end OCR method that unifies text-centric and vision-centric approaches through comprehensive data engineering and a two-stage SFT-RL training framework with domain-specific reward strategies. AI-generated summary The development of large vision language models drives the demand for managing,…",
    "ai_summary": "",
    "ai_generated": false,
    "tags": [],
    "hot_score": 15,
    "sources": [
      "HF Trending Papers"
    ]
  },
  {
    "title": "Segment Length Matters: A Study of Segment Lengths on Audio Fingerprinting Performance",
    "url": "https://huggingface.co/papers/2601.17690",
    "source": "HF Trending Papers",
    "published_at": "2026-01-30",
    "raw_snippet": "Neural audio fingerprinting performance varies with segment length, with short segments (0.5-second) generally providing better retrieval accuracy, and large language models showing promise in recommending optimal segment durations. AI-generated summary Audio fingerprinting provides an identifiable representation of ac…",
    "ai_summary": "",
    "ai_generated": false,
    "tags": [],
    "hot_score": 15,
    "sources": [
      "HF Trending Papers"
    ]
  },
  {
    "title": "PRISM: Learning Design Knowledge from Data for Stylistic Design Improvement",
    "url": "https://huggingface.co/papers/2601.11747",
    "source": "HF Trending Papers",
    "published_at": "2026-01-30",
    "raw_snippet": "PRISM leverages design data to create a knowledge base for improving graphic designs based on natural language instructions, achieving superior style alignment compared to existing methods. AI-generated summary Graphic design often involves exploring different stylistic directions, which can be time-consuming for non-e…",
    "ai_summary": "",
    "ai_generated": false,
    "tags": [],
    "hot_score": 15,
    "sources": [
      "HF Trending Papers"
    ]
  },
  {
    "title": "ConceptMoE: Adaptive Token-to-Concept Compression for Implicit Compute Allocation",
    "url": "https://huggingface.co/papers/2601.21420",
    "source": "HF Trending Papers",
    "published_at": "2026-01-30",
    "raw_snippet": "ConceptMoE dynamically allocates computation by merging similar tokens into concept representations, improving both performance and efficiency in large language models through adaptive processing and reduced attention computation. AI-generated summary Large language models allocate uniform computation across all tokens…",
    "ai_summary": "",
    "ai_generated": false,
    "tags": [],
    "hot_score": 15,
    "sources": [
      "HF Trending Papers"
    ]
  },
  {
    "title": "Self-Improving Pretraining: using post-trained models to pretrain better models",
    "url": "https://huggingface.co/papers/2601.21343",
    "source": "HF Trending Papers",
    "published_at": "2026-01-30",
    "raw_snippet": "A reinforcement learning-based pretraining method improves language model safety, factuality, and quality by evaluating generations through a combination of model rollouts, original suffixes, and rewritten suffixes. AI-generated summary Ensuring safety, factuality and overall quality in the generations of large languag…",
    "ai_summary": "",
    "ai_generated": false,
    "tags": [],
    "hot_score": 15,
    "sources": [
      "HF Trending Papers"
    ]
  },
  {
    "title": "Scaling Embeddings Outperforms Scaling Experts in Language Models",
    "url": "https://huggingface.co/papers/2601.21204",
    "source": "HF Trending Papers",
    "published_at": "2026-01-30",
    "raw_snippet": "Embedding scaling offers superior sparsity scaling compared to expert scaling in large language models, enabling efficient inference through system optimizations and speculative decoding. AI-generated summary While Mixture-of-Experts (MoE) architectures have become the standard for sparsity scaling in large language mo…",
    "ai_summary": "",
    "ai_generated": false,
    "tags": [],
    "hot_score": 15,
    "sources": [
      "HF Trending Papers"
    ]
  },
  {
    "title": "Qwen3-ASR Technical Report",
    "url": "https://huggingface.co/papers/2601.21337",
    "source": "HF Trending Papers",
    "published_at": "2026-01-30",
    "raw_snippet": "The Qwen3-ASR family introduces speech recognition models with language identification capabilities and a non-autoregressive forced alignment model, achieving state-of-the-art performance and efficient processing. AI-generated summary In this report, we introduce Qwen3-ASR family, which includes two powerful all-in-one…",
    "ai_summary": "",
    "ai_generated": false,
    "tags": [],
    "hot_score": 15,
    "sources": [
      "HF Trending Papers"
    ]
  },
  {
    "title": "MAD: Modality-Adaptive Decoding for Mitigating Cross-Modal Hallucinations in Multimodal Large Language Models",
    "url": "https://huggingface.co/papers/2601.21181",
    "source": "HF Trending Papers",
    "published_at": "2026-01-30",
    "raw_snippet": "Multimodal Large Language Models suffer from cross-modal hallucinations where one modality incorrectly influences generation from another, leading to fabricated outputs; this exposes a fundamental deficiency in modality-interaction control. To address this, a training-free method called Modality-Adaptive Decoding (MAD)…",
    "ai_summary": "",
    "ai_generated": false,
    "tags": [],
    "hot_score": 15,
    "sources": [
      "HF Trending Papers"
    ]
  },
  {
    "title": "DynamicVLA: A Vision-Language-Action Model for Dynamic Object Manipulation",
    "url": "https://huggingface.co/papers/2601.22153",
    "source": "HF Trending Papers",
    "published_at": "2026-01-30",
    "raw_snippet": "DynamicVLA addresses dynamic object manipulation challenges through a compact vision-language-action model with temporal reasoning and closed-loop adaptation, supported by a new benchmark for dynamic manipulation tasks. AI-generated summary Manipulating dynamic objects remains an open challenge for Vision-Language-Acti…",
    "ai_summary": "",
    "ai_generated": false,
    "tags": [],
    "hot_score": 15,
    "sources": [
      "HF Trending Papers"
    ]
  },
  {
    "title": "DeepSearchQA: Bridging the Comprehensiveness Gap for Deep Research Agents",
    "url": "https://huggingface.co/papers/2601.20975",
    "source": "HF Trending Papers",
    "published_at": "2026-01-30",
    "raw_snippet": "DeepSearchQA presents a 900-prompt benchmark evaluating agents on complex multi-step information-seeking tasks requiring systematic information collation, deduplication, and reasoning about stopping criteria across 17 fields. AI-generated summary We introduce DeepSearchQA, a 900-prompt benchmark for evaluating agents o…",
    "ai_summary": "",
    "ai_generated": false,
    "tags": [],
    "hot_score": 15,
    "sources": [
      "HF Trending Papers"
    ]
  },
  {
    "title": "MMFineReason: Closing the Multimodal Reasoning Gap via Open Data-Centric Methods",
    "url": "https://huggingface.co/papers/2601.21821",
    "source": "HF Trending Papers",
    "published_at": "2026-01-30",
    "raw_snippet": "A large-scale multimodal reasoning dataset called MMFineReason is introduced to improve vision language models' performance through high-quality reasoning annotations and demonstrates superior parameter efficiency in fine-tuned models. AI-generated summary Recent advances in Vision Language Models (VLMs) have driven si…",
    "ai_summary": "",
    "ai_generated": false,
    "tags": [],
    "hot_score": 15,
    "sources": [
      "HF Trending Papers"
    ]
  },
  {
    "title": "WorldBench: Disambiguating Physics for Diagnostic Evaluation of World Models",
    "url": "https://huggingface.co/papers/2601.21282",
    "source": "HF Trending Papers",
    "published_at": "2026-01-30",
    "raw_snippet": "WorldBench is introduced as a video-based benchmark for disentangled evaluation of physical reasoning in generative models, revealing specific failure patterns in current state-of-the-art video world models. AI-generated summary Recent advances in generative foundational models, often termed \"world models,\" have propel…",
    "ai_summary": "",
    "ai_generated": false,
    "tags": [],
    "hot_score": 15,
    "sources": [
      "HF Trending Papers"
    ]
  },
  {
    "title": "Exploring Reasoning Reward Model for Agents",
    "url": "https://huggingface.co/papers/2601.22154",
    "source": "HF Trending Papers",
    "published_at": "2026-01-30",
    "raw_snippet": "Agent-RRM, a multi-faceted reward model, provides structured feedback for agentic trajectories through reasoning traces, critiques, and performance scores, with unified feedback integration showing superior performance across diverse benchmarks. AI-generated summary Agentic Reinforcement Learning (Agentic RL) has achie…",
    "ai_summary": "",
    "ai_generated": false,
    "tags": [],
    "hot_score": 15,
    "sources": [
      "HF Trending Papers"
    ]
  },
  {
    "title": "VTC-R1: Vision-Text Compression for Efficient Long-Context Reasoning",
    "url": "https://huggingface.co/papers/2601.22069",
    "source": "HF Trending Papers",
    "published_at": "2026-01-30",
    "raw_snippet": "VTC-R1 enables efficient long-context reasoning by compressing textual traces into compact images and iteratively feeding them back into vision-language models as optical memory, achieving significant speedup without sacrificing performance. AI-generated summary Long-context reasoning has significantly empowered large…",
    "ai_summary": "",
    "ai_generated": false,
    "tags": [],
    "hot_score": 15,
    "sources": [
      "HF Trending Papers"
    ]
  },
  {
    "title": "WebArbiter: A Principle-Guided Reasoning Process Reward Model for Web Agents",
    "url": "https://huggingface.co/papers/2601.21872",
    "source": "HF Trending Papers",
    "published_at": "2026-01-30",
    "raw_snippet": "WebArbiter introduces a reasoning-first WebPRM that formulates reward modeling as text generation to improve web navigation through structured justifications and preference verdicts, outperforming existing baselines in complex web environments. AI-generated summary Web agents hold great potential for automating complex…",
    "ai_summary": "",
    "ai_generated": false,
    "tags": [],
    "hot_score": 15,
    "sources": [
      "HF Trending Papers"
    ]
  },
  {
    "title": "Beyond Imitation: Reinforcement Learning for Active Latent Planning",
    "url": "https://huggingface.co/papers/2601.21598",
    "source": "HF Trending Papers",
    "published_at": "2026-01-30",
    "raw_snippet": "Active latent planning method improves reasoning accuracy and efficiency by modeling latent token supervision as conditional VAE and using reinforcement learning with coherence rewards. AI-generated summary Aiming at efficient and dense chain-of-thought (CoT) reasoning, latent reasoning methods fine-tune Large Language…",
    "ai_summary": "",
    "ai_generated": false,
    "tags": [],
    "hot_score": 15,
    "sources": [
      "HF Trending Papers"
    ]
  },
  {
    "title": "Generation Enhances Understanding in Unified Multimodal Models via Multi-Representation Generation",
    "url": "https://huggingface.co/papers/2601.21406",
    "source": "HF Trending Papers",
    "published_at": "2026-01-30",
    "raw_snippet": "UniMRG enhances unified multimodal models by training them to generate multiple visual representations, improving both understanding and generation capabilities through complementary information capture. AI-generated summary Unified Multimodal Models (UMMs) integrate both visual understanding and generation within a si…",
    "ai_summary": "",
    "ai_generated": false,
    "tags": [],
    "hot_score": 15,
    "sources": [
      "HF Trending Papers"
    ]
  },
  {
    "title": "Typhoon-S: Minimal Open Post-Training for Sovereign Large Language Models",
    "url": "https://huggingface.co/papers/2601.18129",
    "source": "HF Trending Papers",
    "published_at": "2026-01-30",
    "raw_snippet": "A minimal post-training approach using supervised fine-tuning, on-policy distillation, and small-scale reinforcement fine-tuning enables the development of high-quality sovereign language models with reduced resource requirements. AI-generated summary Large language models (LLMs) have progressed rapidly; however, most…",
    "ai_summary": "",
    "ai_generated": false,
    "tags": [],
    "hot_score": 15,
    "sources": [
      "HF Trending Papers"
    ]
  },
  {
    "title": "Language-based Trial and Error Falls Behind in the Era of Experience",
    "url": "https://huggingface.co/papers/2601.21754",
    "source": "HF Trending Papers",
    "published_at": "2026-01-30",
    "raw_snippet": "A novel framework called SCOUT is introduced that uses lightweight scouts to reduce exploration costs for large language models in nonlinguistic environments, enabling improved performance through supervised fine-tuning and reinforcement learning. AI-generated summary While Large Language Models (LLMs) excel in languag…",
    "ai_summary": "",
    "ai_generated": false,
    "tags": [],
    "hot_score": 15,
    "sources": [
      "HF Trending Papers"
    ]
  },
  {
    "title": "Llama-3.1-FoundationAI-SecurityLLM-Reasoning-8B Technical Report",
    "url": "https://huggingface.co/papers/2601.21051",
    "source": "HF Trending Papers",
    "published_at": "2026-01-30",
    "raw_snippet": "A two-stage trained cybersecurity reasoning model achieves competitive performance on specialized tasks while maintaining general capabilities through supervised fine-tuning and reinforcement learning from verifiable rewards. AI-generated summary We present Foundation-Sec-8B-Reasoning, the first open-source native reas…",
    "ai_summary": "",
    "ai_generated": false,
    "tags": [],
    "hot_score": 15,
    "sources": [
      "HF Trending Papers"
    ]
  },
  {
    "title": "Introducing NVIDIA Cosmos Policy for Advanced Robot Control",
    "url": "https://huggingface.co/blog/nvidia/cosmos-policy-for-robot-control",
    "source": "Hugging Face Blog",
    "published_at": "2026-01-29",
    "raw_snippet": "",
    "ai_summary": "",
    "ai_generated": false,
    "tags": [],
    "hot_score": 14,
    "sources": [
      "Hugging Face Blog"
    ]
  },
  {
    "title": "Introducing Daggr: Chain apps programmatically, inspect visually",
    "url": "https://huggingface.co/blog/daggr",
    "source": "Hugging Face Blog",
    "published_at": "2026-01-29",
    "raw_snippet": "",
    "ai_summary": "",
    "ai_generated": false,
    "tags": [],
    "hot_score": 14,
    "sources": [
      "Hugging Face Blog"
    ]
  },
  {
    "title": "We Got Claude to Build CUDA Kernels and teach open models!",
    "url": "https://huggingface.co/blog/upskill",
    "source": "Hugging Face Blog",
    "published_at": "2026-01-28",
    "raw_snippet": "",
    "ai_summary": "",
    "ai_generated": false,
    "tags": [],
    "hot_score": 13,
    "sources": [
      "Hugging Face Blog"
    ]
  },
  {
    "title": "Architectural Choices in China's Open-Source AI Ecosystem: Building Beyond DeepSeek",
    "url": "https://huggingface.co/blog/huggingface/one-year-since-the-deepseek-moment-blog-2",
    "source": "Hugging Face Blog",
    "published_at": "2026-01-27",
    "raw_snippet": "",
    "ai_summary": "",
    "ai_generated": false,
    "tags": [],
    "hot_score": 13,
    "sources": [
      "Hugging Face Blog"
    ]
  }
]