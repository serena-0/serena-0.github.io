[
  {
    "title": "OpenAI：以后大家用AI赚的钱，我可能要抽成",
    "url": "https://www.jiqizhixin.com/articles/2026-01-23-10",
    "source": "机器之心",
    "published_at": "2026-01-23",
    "raw_snippet": "",
    "ai_summary": "",
    "ai_generated": false,
    "tags": [],
    "hot_score": 6,
    "sources": [
      "机器之心"
    ]
  },
  {
    "title": "陈天奇、贾扬清点赞：Vibe Coding版PyTorch，连论文都是AI写的",
    "url": "https://www.jiqizhixin.com/articles/2026-01-23-9",
    "source": "机器之心",
    "published_at": "2026-01-23",
    "raw_snippet": "",
    "ai_summary": "",
    "ai_generated": false,
    "tags": [],
    "hot_score": 6,
    "sources": [
      "机器之心"
    ]
  },
  {
    "title": "思维链太长拖慢推理？把它「画」进隐空间！新框架RoT探索大模型隐空间推理新范式",
    "url": "https://www.jiqizhixin.com/articles/2026-01-23-8",
    "source": "机器之心",
    "published_at": "2026-01-23",
    "raw_snippet": "",
    "ai_summary": "",
    "ai_generated": false,
    "tags": [],
    "hot_score": 6,
    "sources": [
      "机器之心"
    ]
  },
  {
    "title": "Gated Sparse Attention: Combining Computational Efficiency with Training Stability for Long-Context Language Models",
    "url": "https://arxiv.org/abs/2601.15305",
    "source": "arXiv cs.AI",
    "published_at": "2026-01-23",
    "raw_snippet": "arXiv:2601.15305v1 Announce Type: new Abstract: The computational burden of attention in long-context language models has motivated two largely independent lines of work: sparse attention mechanisms that reduce complexity by attending to selected tokens, and gated attention variants that improve training sta-bility whi…",
    "ai_summary": "",
    "ai_generated": false,
    "tags": [],
    "hot_score": 5,
    "sources": [
      "arXiv cs.AI"
    ]
  },
  {
    "title": "Uncovering Latent Bias in LLM-Based Emergency Department Triage Through Proxy Variables",
    "url": "https://arxiv.org/abs/2601.15306",
    "source": "arXiv cs.AI",
    "published_at": "2026-01-23",
    "raw_snippet": "arXiv:2601.15306v1 Announce Type: new Abstract: Recent advances in large language models (LLMs) have enabled their integration into clinical decision-making; however, hidden biases against patients across racial, social, economic, and clinical backgrounds persist. In this study, we investigate bias in LLM-based medical…",
    "ai_summary": "",
    "ai_generated": false,
    "tags": [],
    "hot_score": 5,
    "sources": [
      "arXiv cs.AI"
    ]
  },
  {
    "title": "DeepSurvey-Bench: Evaluating Academic Value of Automatically Generated Scientific Survey",
    "url": "https://arxiv.org/abs/2601.15307",
    "source": "arXiv cs.AI",
    "published_at": "2026-01-23",
    "raw_snippet": "arXiv:2601.15307v1 Announce Type: new Abstract: The rapid development of automated scientific survey generation technology has made it increasingly important to establish a comprehensive benchmark to evaluate the quality of generated surveys.Nearly all existing evaluation benchmarks rely on flawed selection criteria su…",
    "ai_summary": "",
    "ai_generated": false,
    "tags": [],
    "hot_score": 5,
    "sources": [
      "arXiv cs.AI",
      "arXiv cs.CL"
    ]
  },
  {
    "title": "Aeon: High-Performance Neuro-Symbolic Memory Management for Long-Horizon LLM Agents",
    "url": "https://arxiv.org/abs/2601.15311",
    "source": "arXiv cs.AI",
    "published_at": "2026-01-23",
    "raw_snippet": "arXiv:2601.15311v1 Announce Type: new Abstract: Large Language Models (LLMs) are fundamentally constrained by the quadratic computational cost of self-attention and the \"Lost in the Middle\" phenomenon, where reasoning capabilities degrade as context windows expand. Existing solutions, primarily \"Flat RAG\" architectures…",
    "ai_summary": "",
    "ai_generated": false,
    "tags": [],
    "hot_score": 5,
    "sources": [
      "arXiv cs.AI"
    ]
  },
  {
    "title": "The Paradigm Shift: A Comprehensive Survey on Large Vision Language Models for Multimodal Fake News Detection",
    "url": "https://arxiv.org/abs/2601.15316",
    "source": "arXiv cs.AI",
    "published_at": "2026-01-23",
    "raw_snippet": "arXiv:2601.15316v1 Announce Type: new Abstract: In recent years, the rapid evolution of large vision-language models (LVLMs) has driven a paradigm shift in multimodal fake news detection (MFND), transforming it from traditional feature-engineering approaches to unified, end-to-end multimodal reasoning frameworks. Early…",
    "ai_summary": "",
    "ai_generated": false,
    "tags": [],
    "hot_score": 5,
    "sources": [
      "arXiv cs.AI",
      "arXiv cs.CV"
    ]
  },
  {
    "title": "Replayable Financial Agents: A Determinism-Faithfulness Assurance Harness for Tool-Using LLM Agents",
    "url": "https://arxiv.org/abs/2601.15322",
    "source": "arXiv cs.AI",
    "published_at": "2026-01-23",
    "raw_snippet": "arXiv:2601.15322v1 Announce Type: new Abstract: LLM agents struggle with regulatory audit replay: when asked to reproduce a flagged transaction decision with identical inputs, most deployments fail to return consistent results. This paper introduces the Determinism-Faithfulness Assurance Harness (DFAH), a framework for…",
    "ai_summary": "",
    "ai_generated": false,
    "tags": [],
    "hot_score": 5,
    "sources": [
      "arXiv cs.AI",
      "arXiv cs.CL"
    ]
  },
  {
    "title": "Prometheus Mind: Retrofitting Memory to Frozen Language Models",
    "url": "https://arxiv.org/abs/2601.15324",
    "source": "arXiv cs.AI",
    "published_at": "2026-01-23",
    "raw_snippet": "arXiv:2601.15324v1 Announce Type: new Abstract: Adding memory to pretrained language models typically requires architectural changes or weight modification. We present Prometheus Mind, which retrofits memory to a frozen Qwen3-4B using 11 modular adapters (530MB, 7% overhead) -- fully reversible by removing the adapters…",
    "ai_summary": "",
    "ai_generated": false,
    "tags": [],
    "hot_score": 5,
    "sources": [
      "arXiv cs.AI"
    ]
  },
  {
    "title": "Logic Programming on Knowledge Graph Networks And its Application in Medical Domain",
    "url": "https://arxiv.org/abs/2601.15347",
    "source": "arXiv cs.AI",
    "published_at": "2026-01-23",
    "raw_snippet": "arXiv:2601.15347v1 Announce Type: new Abstract: The rash development of knowledge graph research has brought big driving force to its application in many areas, including the medicine and healthcare domain. However, we have found that the application of some major information processing techniques on knowledge graph st…",
    "ai_summary": "",
    "ai_generated": false,
    "tags": [],
    "hot_score": 5,
    "sources": [
      "arXiv cs.AI",
      "arXiv cs.CL",
      "arXiv cs.LG"
    ]
  },
  {
    "title": "GeMM-GAN: A Multimodal Generative Model Conditioned on Histopathology Images and Clinical Descriptions for Gene Expression Profile Generation",
    "url": "https://arxiv.org/abs/2601.15392",
    "source": "arXiv cs.AI",
    "published_at": "2026-01-23",
    "raw_snippet": "arXiv:2601.15392v1 Announce Type: new Abstract: Biomedical research increasingly relies on integrating diverse data modalities, including gene expression profiles, medical images, and clinical metadata. While medical images and clinical metadata are routinely collected in clinical practice, gene expression data present…",
    "ai_summary": "",
    "ai_generated": false,
    "tags": [],
    "hot_score": 5,
    "sources": [
      "arXiv cs.AI",
      "arXiv cs.CV",
      "arXiv cs.LG"
    ]
  },
  {
    "title": "Beyond Prompting: Efficient and Robust Contextual Biasing for Speech LLMs via Logit-Space Integration (LOGIC)",
    "url": "https://arxiv.org/abs/2601.15397",
    "source": "arXiv cs.AI",
    "published_at": "2026-01-23",
    "raw_snippet": "arXiv:2601.15397v1 Announce Type: new Abstract: The rapid emergence of new entities -- driven by cultural shifts, evolving trends, and personalized user data -- poses a significant challenge for existing Speech Large Language Models (Speech LLMs). While these models excel at general conversational tasks, their static t…",
    "ai_summary": "",
    "ai_generated": false,
    "tags": [],
    "hot_score": 5,
    "sources": [
      "arXiv cs.AI",
      "arXiv cs.CL"
    ]
  }
]